{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Basket Analysis on Instacard Dataset\n",
    "### Using UMAP and Tensorflow Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data from _InstaCard 2017_ dataset:\n",
    "\"The Instacart Online Grocery Shopping Dataset 2017‚Äù<br/>Accessed from https://www.instacart.com/datasets/grocery-shopping-2017 on March 23, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_items = pd.read_csv(\"instacart_2017_05_01/order_products__train.csv\")\n",
    "insta_products = pd.read_csv(\"instacart_2017_05_01/products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalize and clean dataset. Use only the train ```eval_set```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"order_id\", \"product_id\", \"product_name\"]\n",
    "df = insta_items.merge(insta_products, on=\"product_id\", how=\"left\")\n",
    "df = df[columns_to_keep]\n",
    "df = df.dropna()\n",
    "df[\"product_id\"] = (\n",
    "    df[\"product_id\"].astype(\"int\").astype(\"str\")\n",
    ")  # Conver product key to str for Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id      131209\n",
       "product_id     39123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"order_id\", \"product_id\"]].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the training dataset to a sample of 25_000 orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "sample_orders = random.sample(df[\"order_id\"].unique().tolist(), 25_000)\n",
    "len(sample_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a list of the ```product_id``` for all the sample orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max products in one order:  76\n"
     ]
    }
   ],
   "source": [
    "purchases = (\n",
    "    df[df[\"order_id\"].isin(sample_orders)]\n",
    "    .groupby(\"order_id\")[\"product_id\"]\n",
    "    .apply(list)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(\"Max products in one order: \", max(len(i) for i in purchases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Word2Vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=8230, size=200, alpha=0.03)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    window=50,\n",
    "    size=200,\n",
    "    sg=0,\n",
    "    hs=0,\n",
    "    negative=10,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    seed=42,\n",
    "    workers=4,\n",
    "    min_count=5,\n",
    ")\n",
    "\n",
    "model.build_vocab(purchases)\n",
    "model.train(purchases, total_examples=model.corpus_count, epochs=20, report_delay=1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ```product_id``` and ```product_name``` dictionary to be used for TensorFlow projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_dict = df.groupby(\"product_id\")[\"product_name\"].first().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ```vecs.tsv``` and ```meta.tsv``` files to be imported to https://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-746f9f4b66ae>:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  out_vect.write('\\t'.join([str(j) for j in model[i]]) + \"\\n\")\n"
     ]
    }
   ],
   "source": [
    "out_vect = io.open(\"vecs.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_meta = io.open(\"meta.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for i in model.wv.vocab:\n",
    "    out_meta.write(products_dict[i] + \": \" + str(i) + \"\\n\")\n",
    "    out_vect.write(\"\\t\".join([str(j) for j in model[i]]) + \"\\n\")\n",
    "\n",
    "out_vect.close()\n",
    "out_meta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
